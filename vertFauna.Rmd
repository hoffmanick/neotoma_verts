---
title: "Neotoma Vertebrates Overview"
author: "Nick Hoffman"
date: '`r Sys.Date()`'
output: 
  html_document:
    df_print: paged
    toc: true
    toc_depth: 1
    toc_float: true
    theme: journal
---
<style>

.nav {
display: grid;
grid-template-columns: 1fr 1fr 1fr;
}

.nav:before {
display: none;
}

.newgrid {

display: grid;
grid-template-columns: 1fr 10fr;
}

#mammals .leaflet {
  height: 700px !important ;
}
</style>

```{r, results='asis', echo = F}
toc_depth <- rmarkdown::metadata$output$html_document$toc_depth
sel <- paste0("h",(toc_depth+1):10, collapse = " > span, ")
cat(paste0("<style>",
           sel, 
           " > .header-section-number { display: none; } </style>"))
```


```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = FALSE,
	message = FALSE,
	warning = FALSE
)
```

```{r libraries}
library(httr)
library(jsonlite)
library(tidyverse)
library(leaflet)
library(sf)
library(ggplot2)
library(DT)
library(shiny)
library(plotly)
```

```{r download-tables}


tables = c("sites","datasets","collectionunits","datasetdatabases","constituentdatabases","datasettypes","analysisunits","chroncontrols","agetypes","sampleages","samples")

for (q in seq(length(tables))) {
tablename=tables[q]

length_analysisunits = content(GET(paste0("https://api.neotomadb.org/v2.0/data/dbtables/",tablename,"?count=true")))$data

divider = 80000
num_reps = ceiling(as.numeric(length_analysisunits[[1]]$count)/divider)

analysisunits = list()
for (i in seq(num_reps)) {
  start= (i-1)*divider
  end = divider
  newnits = content(GET(paste0("https://api.neotomadb.org/v2.0/data/dbtables/",tablename,"?count=false&offset=",start,"&limit=",end)))$data
 
  if (!is.null(newnits)) {
  analysisunits = append(analysisunits,newnits)
  }
  }


analysis_mat = matrix(nrow=length(analysisunits),ncol=length(analysisunits[[1]]))

for (i in seq(length(analysisunits))) {
  for(j in seq(length(analysisunits[[1]])) ) {
    if (!is.null(analysisunits[[i]][[j]])) {
      analysis_mat[i,j] = analysisunits[[i]][[j]]
    }}}


analysis_df = as.data.frame(analysis_mat)


names(analysis_df) =names(newnits[[1]])

assign(paste0(tablename,"_df"), analysis_df)}
```

# Space

## Spatial Coverage

```{r space-format}

vert_datasets = datasets_df %>% left_join(datasettypes_df, by=join_by(datasettypeid)) %>% left_join(datasetdatabases_df,by=join_by(datasetid)) %>% dplyr::filter(datasettype=="vertebrate fauna") %>% left_join(collectionunits_df, by=join_by(collectionunitid)) %>% left_join(sites_df, by=join_by(siteid)) %>% left_join(constituentdatabases_df,by=join_by(databaseid))
```

```{r gather-chrons}


chron_string1 = paste0(vert_datasets$datasetid[1:1340], collapse=",")
chron_string2 = paste0(vert_datasets$datasetid[1341:2680], collapse=",")
chron_string3 = paste0(vert_datasets$datasetid[2681:4020], collapse=",")
chron_string4 = paste0(vert_datasets$datasetid[4021:5337], collapse=",")

chrons1 = content(GET(paste0("https://api.neotomadb.org/v2.0/data/datasets/",chron_string1,"/chronologies")))$data
chrons2 = content(GET(paste0("https://api.neotomadb.org/v2.0/data/datasets/",chron_string2,"/chronologies")))$data
chrons3 = content(GET(paste0("https://api.neotomadb.org/v2.0/data/datasets/",chron_string3,"/chronologies")))$data
chrons4 = content(GET(paste0("https://api.neotomadb.org/v2.0/data/datasets/",chron_string4,"/chronologies")))$data

all_chrons = chrons1 %>% append(chrons2) %>% append(chrons3) %>% append(chrons4)


dat1 = content(GET(paste0("https://api.neotomadb.org/v2.0/data/downloads/",chron_string1,"?limit=9999")))$data
dat2 = content(GET(paste0("https://api.neotomadb.org/v2.0/data/downloads/",chron_string2,"?limit=9999")))$data
dat3 = content(GET(paste0("https://api.neotomadb.org/v2.0/data/downloads/",chron_string3,"?limit=9999")))$data
dat4 = content(GET(paste0("https://api.neotomadb.org/v2.0/data/downloads/",chron_string4,"?limit=9999")))$data


all_dat = dat1 %>% append(dat2) %>% append(dat3) %>% append(dat4)


count=0
for (i in seq(length(all_chrons))) {
  for (j in seq(length(all_chrons[[i]]$chronology$datasets))) {
    count = count + 1
  }
}

chron_mat = matrix(nrow=count,ncol=10)

count2=0
for (i in seq(length(all_chrons))) {
  for (j in seq(length(all_chrons[[i]]$chronology$datasets))) {
    count2 = count2 + 1
    
    if (!is.null(all_chrons[[i]]$chronology$agetype)) {
    chron_mat[[count2, 1]] = all_chrons[[i]]$chronology$agetype
    }
    
    if (!is.null(all_chrons[[i]]$chronology$modelType)) {
    chron_mat[[count2, 2]] = all_chrons[[i]]$chronology$modelType
    }
    
    if (!is.null(all_chrons[[i]]$chronology$chronologyid)) {
    chron_mat[[count2, 3]] = all_chrons[[i]]$chronology$chronologyid
    }
    
    if (!is.null(all_chrons[[i]]$chronology$datePrepared)) {
    chron_mat[[count2, 4]] = all_chrons[[i]]$chronology$datePrepared
    }
    
    if (!is.null(all_chrons[[i]]$chronology$chronologyName)) {
    chron_mat[[count2, 5]] = all_chrons[[i]]$chronology$chronologyName
    }
    
    if (!is.null(all_chrons[[i]]$chronology$chronologynotes)) {
    chron_mat[[count2, 6]] = all_chrons[[i]]$chronology$chronologynotes
    }
    
    if (!is.null(all_chrons[[i]]$chronology$datasets[[j]]$datasetid)) {
    chron_mat[[count2, 7]] = all_chrons[[i]]$chronology$datasets[[j]]$datasetid
    }
    
    if (!is.null(all_chrons[[i]]$chronology$datasets[[j]]$datasettype)) {
    chron_mat[[count2, 8]] = all_chrons[[i]]$chronology$datasets[[j]]$datasettype
    }

    if (!is.null(all_chrons[[i]]$chronology$reliableagespan$older)) {
    chron_mat[[count2, 9]] = all_chrons[[i]]$chronology$reliableagespan$older
    }
    
    if (!is.null(all_chrons[[i]]$chronology$reliableagespan$younger)) {
    chron_mat[[count2, 10]] = all_chrons[[i]]$chronology$reliableagespan$younger
    }
    
  }   
}

chron_df = as.data.frame(chron_mat)

names(chron_df) = c("agetype","modelType","chronologyid","datePrepared","chronologyName","chronologynotes","datasetid","datasettype","older","younger")


## 104 datasets without ages
## 3256 faunmap 1.1
## 1560 syverson-blois bounds and 1560 events
## 1358 faunmap 2.1


num_datasets = length(vert_datasets[[1]])
```

There are `r num_datasets` vertebrate fauna datasets in Neotoma. Below is a map of all the sites in Neotoma corresponding to these datasets, colored by the constituent database to which they correspond.

```{r pressure, echo=FALSE}


point_vert_datasets = vert_datasets %>% dplyr::filter(latitudesouth == latitudenorth & longitudeeast == longitudewest) %>% st_as_sf(coords=c("longitudeeast","latitudesouth"),crs="4326")

poly_vert_datasets = vert_datasets %>% dplyr::filter(!datasetid %in% point_vert_datasets$datasetid & !is.na(longitudeeast))

poly_vert_datasets = poly_vert_datasets %>% mutate(latitudesouth = as.numeric(latitudesouth),
                            latitudenorth = as.numeric(latitudenorth),
                            longitudeeast = as.numeric(longitudeeast),
                            longitudewest = as.numeric(longitudewest))

polygons <- lapply(1:nrow(poly_vert_datasets), function(i) {
  coords <- matrix(c(
    poly_vert_datasets$longitudewest[i], poly_vert_datasets$latitudesouth[i],
    poly_vert_datasets$longitudeeast[i], poly_vert_datasets$latitudesouth[i],
    poly_vert_datasets$longitudeeast[i], poly_vert_datasets$latitudenorth[i],
    poly_vert_datasets$longitudewest[i], poly_vert_datasets$latitudenorth[i],
    poly_vert_datasets$longitudewest[i], poly_vert_datasets$latitudesouth[i]  # Close the polygon
  ), ncol = 2, byrow = TRUE)
  
  st_polygon(list(coords))
})

poly_vert_datasets <- st_sf(poly_vert_datasets, geometry = st_sfc(polygons, crs = 4326))

pal <- colorFactor(palette = "Set1", domain = point_vert_datasets$databasename)

point_vert_datasets = point_vert_datasets %>% dplyr::mutate(link = paste0("<a target='_blank' href='https://data.neotomadb.org/datasets/",datasetid,"'/>",sitename,"</a>"))
poly_vert_datasets = poly_vert_datasets %>% dplyr::mutate(link = paste0("<a target='_blank' href='https://data.neotomadb.org/datasets/",datasetid,"'/>",sitename,"</a>"))

leaflet() %>%
  addTiles() %>%
    addPolygons(data=poly_vert_datasets,
              fillColor=~pal(databasename),
              color=~pal(databasename),
              weight=2,
              opacity=0.5,
              fillOpacity=0.5,
              popup = ~link) %>%
  addCircleMarkers(data=point_vert_datasets,
                   fillColor=~pal(databasename),
                   stroke=FALSE,
                   radius=3,
                   fillOpacity=0.5,
                   popup = ~link) %>%
   addLegend("bottomright", 
            pal = pal, 
            values = point_vert_datasets$databasename,
            title = "Database Name",
            opacity = 1)


```


The datasets associated with the insect database or which associated with no database (i.e., NA) are:

```{r na-and-ndsu}


vert_datasets %>% dplyr::filter(databaseid %in% c(NA,14)) %>% select(datasetid,collectionunitid,siteid,sitename,databasename) %>% datatable(rownames=FALSE,options = list(pageLength = 12))


```

## Spatial Precision ?

# Time

## Chronologies



```{r chroncount}
##datasetid 24742 has duplicate faunmap 2.1 chronology

agetype_wide = chron_df %>% group_by(datasetid,agetype) %>% summarize() %>% mutate(present = 1) %>% pivot_wider(id_cols=datasetid,names_from=agetype,values_from=present,values_fill=0)

only_rc = agetype_wide %>% dplyr::filter(`Radiocarbon years BP` == 1 &
                                 `Calendar years AD/BC` == 0 &
                                 `Calibrated radiocarbon years BP` == 0 &
                                 `Calendar years BP` == 0) %>% dplyr::mutate(status="only radiocarbon")

cal_raw = agetype_wide %>% dplyr::filter(`Radiocarbon years BP` == 1 &
                                   `Calibrated radiocarbon years BP` == 1)

raw_and = agetype_wide %>% dplyr::filter(`Radiocarbon years BP` == 1 &

                                   `Calendar years BP` == 1) %>%
  rbind(cal_raw) %>% distinct(datasetid) %>% dplyr::mutate(status="radiocarbon and other")

other_age = agetype_wide %>% dplyr::filter(!datasetid %in% c(raw_and$datasetid,only_rc$datasetid ))

only_bp = other_age %>% dplyr::filter(`Radiocarbon years BP` == 0 &
                                 `Calendar years AD/BC` == 0 &
                                 `Calibrated radiocarbon years BP` == 0 &
                                 `Calendar years BP` == 1)  %>% dplyr::mutate(status="only calendar BP")

only_ad = other_age %>% dplyr::filter(`Radiocarbon years BP` == 0 &
                                 `Calendar years AD/BC` == 1 &
                                 `Calibrated radiocarbon years BP` == 0 &
                                 `Calendar years BP` == 0)  %>% dplyr::mutate(status="only calendar AD")

only_cal = other_age %>% dplyr::filter(`Radiocarbon years BP` == 0 &
                                 `Calendar years AD/BC` == 0 &
                                 `Calibrated radiocarbon years BP` == 1 &
                                 `Calendar years BP` == 0)  %>% dplyr::mutate(status="only calibrated")


other_other_age = other_age %>% dplyr::filter(!datasetid %in% c(only_cal$datasetid,only_ad$datasetid,only_bp$datasetid))  %>% dplyr::mutate(status="other")

status_age = only_rc %>% rbind(raw_and) %>% rbind(only_cal) %>% rbind(only_ad) %>% rbind(only_bp) %>% rbind(other_other_age) %>% left_join(datasetdatabases_df,by=join_by(datasetid)) %>% left_join(constituentdatabases_df,by=join_by(databaseid))


status_age$status <- factor(status_age$status, levels = c("only radiocarbon", "radiocarbon and other", "only calendar BP","only calibrated","only calendar AD","other"))



chron_wide = chron_df %>% dplyr::filter(chronologyid !=14943) %>% mutate(present = 1) %>%  pivot_wider(id_cols=datasetid,names_from=chronologyName,values_from = present, values_fill=0)

number_chron = chron_wide %>% select(!datasetid) %>% rowSums() %>% cbind(chron_wide) 

names(number_chron)[[1]] = "number"

just_one = number_chron %>% dplyr::filter(number == 1)

sy_bl_bounds = chron_wide %>% dplyr::filter(!datasetid %in% just_one$datasetid) %>% dplyr::filter(`Syverson-Blois: bounds` == 1)

## 4 faunmap 21
faunmap_21 = chron_wide %>% dplyr::filter(!datasetid %in% sy_bl_bounds$datasetid  & !datasetid %in% just_one$datasetid) %>% dplyr::filter(`Faunmap 2.1` == 1)

## 17 calibrated
calibrated = chron_wide %>% dplyr::filter(!datasetid %in% sy_bl_bounds$datasetid & !datasetid %in% faunmap_21$datasetid & !datasetid %in% just_one$datasetid) %>% dplyr::filter(`Calibrated Ages` == 1)

## 10 neotoma2
neotoma2 = chron_wide %>% dplyr::filter(!datasetid %in% sy_bl_bounds$datasetid & !datasetid %in% calibrated$datasetid & !datasetid %in% faunmap_21$datasetid & !datasetid %in% just_one$datasetid & !datasetid %in% calibrated$datasetid) %>% dplyr::filter(`Neotoma 2` == 1)


## 13 faunmap 1.1
faun1 = chron_wide %>% dplyr::filter(!datasetid %in% sy_bl_bounds$datasetid & !datasetid %in% calibrated$datasetid & !datasetid %in% faunmap_21$datasetid & !datasetid %in% just_one$datasetid & !datasetid %in% calibrated$datasetid & !datasetid %in% neotoma2$datasetid) %>% dplyr::filter(`FAUNMAP 1.1` == 1)

sybl = chron_df %>% dplyr::filter(datasetid %in% sy_bl_bounds$datasetid & chronologyName == "Syverson-Blois: bounds")
justone = chron_df %>% dplyr::filter(datasetid %in% just_one$datasetid)
fm21 = chron_df %>% dplyr::filter(datasetid %in% faunmap_21$datasetid & chronologyName == "Faunmap 2.1")
calbrat = chron_df %>% dplyr::filter(datasetid %in% calibrated$datasetid & chronologyName == "Calibrated Ages")
neo2 = chron_df %>% dplyr::filter(datasetid %in% neotoma2$datasetid & chronologyName == "Neotoma 2")
fm1 = chron_df %>% dplyr::filter(datasetid %in% faun1$datasetid & chronologyName == "FAUNMAP 1.1")


#chron_wide %>% dplyr::filter(!datasetid %in% sy_bl_bounds$datasetid & !datasetid %in% calibrated$datasetid & !datasetid %in% faunmap_21$datasetid & !datasetid %in% just_one$datasetid & !datasetid %in% neotoma2$datasetid & !datasetid %in% faun1$datasetid) %>% select(where(~ !all(. == 0)))


chosen_chrons = sybl %>% rbind(justone) %>% rbind(fm21) %>% rbind(calbrat) %>% rbind(neo2) %>% rbind(fm1)

random_chrons = chron_df %>% dplyr::filter(!datasetid %in% chosen_chrons$datasetid) %>% distinct(datasetid,.keep_all = TRUE)

all_distinct_chrons = chosen_chrons %>% rbind(random_chrons)

num_only_rc = length(only_rc[[1]])

num_raw_and = length(raw_and[[1]])

```


Of the `r num_datasets` vertebrate fauna datasets in Neotoma, there are a plurality, `r num_only_rc` datasets, which only have a chronology in raw radiocarbon years. There are another `r num_raw_and` which have both a raw radiocarbon chronology and a calibrated chronology (almost all of these are "Calibrated Radiocarbon Years"; three are "Calendar Years BP").



```{r addchron}


ggplot(status_age) +
  geom_bar(mapping=aes(x=status,fill=databasename)) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))

```

## Coverage

To determine temporal coverage of the vertebrate fauna datasets, I had to select chronologies for each dataset. If a dataset only had a single chronology, I chose that. For the rest, this was the order of preference:

* Syverson-Blois bounds
* FAUNMAP 2.1
* Calibrated
* Neotoma 2
* FAUNMAP 1.1

For the remaining 23 datasets, I chose a chronology randomly. I used the reliableagespan values associated with this [API](https://api.neotomadb.org/v2.0/data/datasets/100/chronologies) to get older and younger bounds associated with a dataset. Four of the FAUNMAP 1.1 datasets (IDs = 6450,6861,6972,7833) had NA older and younger bounds, so I removed those. 

Below is a table of the ages of the chronologies I chose.


``` {r howcover}
all_distinct_chrons %>% group_by(chronologyName, agetype) %>% count() %>% arrange(desc(n)) %>% datatable(rownames=FALSE)


all_distinct_chrons_mut = all_distinct_chrons %>% 
  dplyr::mutate(older=as.numeric(older),younger=as.numeric(younger)) %>%
  dplyr::mutate(older = case_when(
    agetype == "Calendar years AD/BC" ~ 1950 - older,
    TRUE ~ older
  )) %>% 
  dplyr::mutate(younger = case_when(
    agetype == "Calendar years AD/BC" ~ 1950 - younger,
    TRUE ~ younger
  )) %>%
  dplyr::mutate(agetype = case_when(
    agetype == "Calendar years AD/BC" ~ "BP mutated",
    TRUE ~ agetype
  ))

adc = all_distinct_chrons_mut %>% left_join(vert_datasets, by=join_by(datasetid)) %>% dplyr::mutate(older = as.numeric(older),younger=as.numeric(younger))

adc = adc %>% dplyr::mutate(period = case_when(
  older < 11625 ~ "Holocene",
  older >= 11625 & younger <= 11625 ~ "Holo/Pleisto",
  younger > 11625 & younger <= 2580000 & older > 11625 & older <= 2580000 ~ "Pleistocene",
  older >= 2580000 & younger <= 2580000 ~ "Pleisto-Plio",
  younger > 2580000 & younger <= 5333000 & older > 2580000 & older <= 5333000 ~ "Pliocene",
  older >= 5333000 & younger <= 5333000 ~ "Plio-Mio",
  younger > 5333000 & younger <= 23030000 & older > 5333000 & older <= 23030000 ~ "Miocene",
))

num_hol = adc %>% dplyr::filter(period=="Holocene") %>% count()
num_hol = num_hol[[1]]

num_holpl = adc %>% dplyr::filter(period=="Holo/Pleisto") %>% count()
num_holpl = num_holpl[[1]]
```

Given these chronologies, we found that most datasets (n= `r num_hol`) are from the Holocene epoch, nearly 1000 span the Holocene and Pleistocene, and nearly another 1000 are within the Pleistocene, with fewer further back in time.

```{r anothnew}

adc$period <- factor(adc$period, levels = c("Holocene", "Holo/Pleisto", "Pleistocene","Pleisto-Plio","Pliocene","Plio-Mio","Miocene"))

adc$databasename = factor(adc$databasename, levels = rev(c(NA,"FAUNMAP","Neotoma Midden Database","Alaskan Archaeofaunas","Neotoma","Faunal Isotope Database","PaleoVertebrates of Latin America","NDSU Insect Database")))

adc = adc %>% dplyr::filter(!is.na(period)) %>%
  group_by(period,databasename) %>% count() %>% arrange(desc(n))

ggplot(data=adc) +
  geom_col(mapping=aes(x=period,y=n,fill=databasename)) +
  labs(y="Number of Records") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))

```

## Temporal Precision

This graph shows dataset-level temporal precision on a log scale. For datasets with an age type of calendar years AD/BC, I converted to BP. There are a few datasets which purport to be in years BP but aren't actually... I think those ones are generally from FID.

```{r collection-chron}


index = seq(length(all_distinct_chrons_mut[[1]]))


all_distinct_chrons_mut = all_distinct_chrons %>% 
  dplyr::mutate(older=as.numeric(older),younger=as.numeric(younger)) %>%
  dplyr::mutate(older = case_when(
    agetype == "Calendar years AD/BC" ~ 1950 - older,
    TRUE ~ older
  )) %>% 
  dplyr::mutate(younger = case_when(
    agetype == "Calendar years AD/BC" ~ 1950 - younger,
    TRUE ~ younger
  )) %>%
  dplyr::mutate(agetype = case_when(
    agetype == "Calendar years AD/BC" ~ "BP mutated",
    TRUE ~ agetype
  ))

all_distinct_chrons_mut = all_distinct_chrons_mut %>% mutate(older=as.numeric(older),younger=as.numeric(younger)) %>% arrange((older)) %>% cbind(index) %>% left_join(datasetdatabases_df,by=join_by(datasetid)) %>% left_join(constituentdatabases_df,by=join_by(databaseid))

all_distinct_chrons_mut = all_distinct_chrons_mut %>% 
  dplyr::mutate(modyounger = case_when(
   younger >0 ~ log(younger,base=10),
   younger <=0 ~ -5),
   modolder = case_when(
   older >0 ~ log(older,base=10),
   older <=0 ~ -4),)

ds_chron = ggplot(all_distinct_chrons_mut) +
  geom_segment(mapping=aes(x=modyounger,
                           xend=modolder,
                           y=index,yend=index,
                           color=databasename,
                           text = paste("datasetID:", datasetid,
                                 "<br>Older:", older,
                                 "<br>Younger:", younger)),linewidth=0.1) +
  #geom_point(mapping=aes(x=log(younger),y=index),color='red') +
  #geom_point(mapping=aes(x=log(older),y=index),color='red') +
  labs(x = "Years BP") +
  scale_x_continuous(breaks = c(1, 3, 5,7), labels = c("10^1", "10^3","10^5","10^7")) +
  guides(color = guide_legend(override.aes = list(
    linetype = 1,   # No line
    shape = 16,     # Solid circle
    linewidth = 5 # Dot size
  ))) +
  theme_bw() +
  coord_cartesian(xlim = c(-0.5, 7))

ggplotly(ds_chron, tooltip="text")


adc_stat = all_distinct_chrons_mut %>% left_join(status_age,by=join_by(datasetid)) 


ds_chron2 = ggplot(adc_stat) +
  geom_segment(mapping=aes(x=modyounger,
                           xend=modolder,
                           y=index,yend=index,
                           color=status,
                           text = paste("datasetID:", datasetid,
                                 "<br>Older:", older,
                                 "<br>Younger:", younger)),linewidth=0.1) +
  #geom_point(mapping=aes(x=log(younger),y=index),color='red') +
  #geom_point(mapping=aes(x=log(older),y=index),color='red') +
  labs(x = "Years BP") +
  scale_x_continuous(breaks = c(1, 3, 5,7), labels = c("10^1", "10^3","10^5","10^7")) +
  guides(color = guide_legend(override.aes = list(
    linetype = 1,   # No line
    shape = 16,     # Solid circle
    linewidth = 5 # Dot size
  ))) +
  theme_bw() +
  coord_cartesian(xlim = c(-0.5, 7))

ggplotly(ds_chron2, tooltip="text")


```


And this graph is log-scale temporal precision of sample ages associated with vertebrate fauna datasets. 


```{r analysis-chron}

analy_chron = sampleages_df %>% dplyr::filter(chronologyid %in% all_distinct_chrons$chronologyid)


samples_abridged = samples_df %>% distinct(sampleid,.keep_all=TRUE)



dcc = analy_chron %>% mutate(older=as.numeric(ageolder),younger=as.numeric(ageyounger)) %>% arrange((older),younger) %>% left_join(samples_abridged,by=join_by(sampleid)) %>% left_join(datasets_df,by=join_by(datasetid)) %>%  left_join(datasetdatabases_df,by=join_by(datasetid)) %>% left_join(constituentdatabases_df,by=join_by(databaseid)) %>% left_join(datasettypes_df,by=join_by(datasettypeid)) %>% dplyr::filter(!is.na(younger)) %>% dplyr::filter(!is.na(older)) %>% dplyr::filter(datasettype=="vertebrate fauna" )

index2 = seq(length(dcc[[1]]))

dcc = dcc %>% cbind(index2)

  #geom_point(mapping=aes(x=log(younger),y=index2),color='red',size=0.05) +
  #geom_point(mapping=aes(x=log(older),y=index2),color='red',size=0.05) +

dcc = dcc %>% 
  dplyr::mutate(modyounger = case_when(
   younger >0 ~ log(younger,base=10),
   younger <=0 ~ -5),
   modolder = case_when(
   older >0 ~ log(older,base=10),
   older <=0 ~ -4),)

dcc_p = ggplot(dcc) +
  geom_segment(mapping=aes(x=modyounger,
                           xend=modolder,
                           y=index2,
                           yend=index2,
                           color=databasename,
                           text = paste("sampleID:", sampleid,
                                 "<br>Older:", older,
                                 "<br>Younger:", younger)),
               alpha=0.4,stroke=NA,linewidth=0.1) + 
  labs(x = "Years BP") +
  scale_x_continuous(breaks = c(1, 3, 5,7), labels = c("10^1", "10^3", "10^5","10^7")) +
  guides(color = guide_legend(override.aes = list(
    linetype = 1,   # No line
    shape = 16,     # Solid circle
    linewidth = 5,
    alpha=1
    
  ))) +
  theme_bw() +
  coord_cartesian(xlim = c(-0.5, 7))


ggplotly(dcc_p, tooltip="text")

```

Should I interpret the values below as AD?

```{r weirods}

dcc %>% dplyr::filter((older <= -75 & younger > older) | younger < -75) %>% select(chronologyid,age,ageyounger,ageolder,databasename) %>% datatable(rownames=FALSE)

```


## Uploads Over Time

Below you can see when a dataset was originally uploaded to Neotoma, based on the recdatecreated field for the dataset. 

```{r when-published}

vert_datasets = vert_datasets %>% dplyr::mutate(dataset_date = date(recdatecreated.x))
vert_datasets = vert_datasets %>% dplyr::mutate(year = year(dataset_date))

ggplot(vert_datasets) +
  geom_bar(mapping=aes(x=year,fill=databasename)) +
  theme_bw() +
  facet_wrap(~databasename, scales="free_y")

```


```{r data-download}

counter=0
for (i in seq(length(all_dat))) {
    for (j in seq(length(all_dat[[i]]$site$collectionunit$dataset$samples))) {
        for (k in seq(length(all_dat[[i]]$site$collectionunit$dataset$samples[[j]]$datum))) {
            counter = counter + 1
        }
    }
}

vert_data_mat = matrix(nrow=counter, ncol=17)


counter2 = 0
for (i in seq(length(all_dat))) {
    for (j in seq(length(all_dat[[i]]$site$collectionunit$dataset$samples))) {
        for (k in seq(length(all_dat[[i]]$site$collectionunit$dataset$samples[[j]]$datum))) {
          counter2 = counter2 + 1
          if(!is.null(all_dat[[i]]$site$collectionunit$dataset$datasetid)) {
            vert_data_mat[[counter2,1]] = all_dat[[i]]$site$collectionunit$dataset$datasetid
          }
          
          if(!is.null(all_dat[[i]]$site$collectionunit$dataset$samples[[j]]$depth)) {
            vert_data_mat[[counter2,2]] = all_dat[[i]]$site$collectionunit$dataset$samples[[j]]$depth
          }
          
          if(!is.null(all_dat[[i]]$site$collectionunit$dataset$samples[[j]]$sampleid)) {
            vert_data_mat[[counter2,3]] = all_dat[[i]]$site$collectionunit$dataset$samples[[j]]$sampleid
          }
          
          if(!is.null(all_dat[[i]]$site$collectionunit$dataset$samples[[j]]$thickness)) {
            vert_data_mat[[counter2,4]] = all_dat[[i]]$site$collectionunit$dataset$samples[[j]]$thickness
          }
          
          if(!is.null(all_dat[[i]]$site$collectionunit$dataset$samples[[j]]$samplename)) {
            vert_data_mat[[counter2,5]] = all_dat[[i]]$site$collectionunit$dataset$samples[[j]]$samplename
          }
          
          if(!is.null(all_dat[[i]]$site$collectionunit$dataset$samples[[j]]$igsn)) {
            vert_data_mat[[counter2,6]] = all_dat[[i]]$site$collectionunit$dataset$samples[[j]]$igsn
          }
          
          if(!is.null(all_dat[[i]]$site$collectionunit$dataset$samples[[j]]$analysisunitid)) {
            vert_data_mat[[counter2,7]] = all_dat[[i]]$site$collectionunit$dataset$samples[[j]]$analysisunitid
          }
          
          if(!is.null(all_dat[[i]]$site$collectionunit$dataset$samples[[j]]$datum[[k]]$units)) {
            vert_data_mat[[counter2,8]] = all_dat[[i]]$site$collectionunit$dataset$samples[[j]]$datum[[k]]$units
          }
          
          if(!is.null(all_dat[[i]]$site$collectionunit$dataset$samples[[j]]$datum[[k]]$value)) {
            vert_data_mat[[counter2,9]] = all_dat[[i]]$site$collectionunit$dataset$samples[[j]]$datum[[k]]$value
          }
          
          if(!is.null(all_dat[[i]]$site$collectionunit$dataset$samples[[j]]$datum[[k]]$context)) {
            vert_data_mat[[counter2,10]] = all_dat[[i]]$site$collectionunit$dataset$samples[[j]]$datum[[k]]$context
          }
          
          if(!is.null(all_dat[[i]]$site$collectionunit$dataset$samples[[j]]$datum[[k]]$element)) {
            vert_data_mat[[counter2,11]] = all_dat[[i]]$site$collectionunit$dataset$samples[[j]]$datum[[k]]$element
          }
          
          if(!is.null(all_dat[[i]]$site$collectionunit$dataset$samples[[j]]$datum[[k]]$taxonid)) {
            vert_data_mat[[counter2,12]] = all_dat[[i]]$site$collectionunit$dataset$samples[[j]]$datum[[k]]$taxonid
          }
          
          if(!is.null(all_dat[[i]]$site$collectionunit$dataset$samples[[j]]$datum[[k]]$symmetry)) {
            vert_data_mat[[counter2,13]] = all_dat[[i]]$site$collectionunit$dataset$samples[[j]]$datum[[k]]$symmetry
          }
          
          if(!is.null(all_dat[[i]]$site$collectionunit$dataset$samples[[j]]$datum[[k]]$taxongroup)) {
            vert_data_mat[[counter2,14]] = all_dat[[i]]$site$collectionunit$dataset$samples[[j]]$datum[[k]]$taxongroup
          }
          
          if(!is.null(all_dat[[i]]$site$collectionunit$dataset$samples[[j]]$datum[[k]]$elementtype)) {
            vert_data_mat[[counter2,15]] = all_dat[[i]]$site$collectionunit$dataset$samples[[j]]$datum[[k]]$elementtype
          }
          
          if(!is.null(all_dat[[i]]$site$collectionunit$dataset$samples[[j]]$datum[[k]]$variablename)) {
            vert_data_mat[[counter2,16]] = all_dat[[i]]$site$collectionunit$dataset$samples[[j]]$datum[[k]]$variablename
          }
          
          if(!is.null(all_dat[[i]]$site$collectionunit$dataset$samples[[j]]$datum[[k]]$ecologicalgroup)) {
            vert_data_mat[[counter2,17]] = all_dat[[i]]$site$collectionunit$dataset$samples[[j]]$datum[[k]]$ecologicalgroup
          }
          
        }
    }
}

all_dat_df = as.data.frame(vert_data_mat)


names(all_dat_df) = c("datasetid","depth","sampleid","thickness","samplename","igsn","analysisunitid","units","value","context","element","taxonid","symmetry","taxongroup","elementtype","variablename","ecologicalgroup")
```

# Taxonomy 

## Taxonomic Precision

I harmonized the data from vertebrate fauna datasets in Neotoma with a table that Val and Jessica made which also described the taxonomic precision of the identification. That table captured 567 of the 2883 taxa described in Neotoma vertebrate fauna datasets (19.67%), and 32,965 of the 78,415 of the observations in the datasets (42.04%). 

Following harmonization with Jessica and Val's table, and dropping those taxa which weren't represented in it, here is a summary of the precision of the vertebrate fauna data overall:

```{r pre-unk}


taxaharm = read.csv('taxon-crosswalk(in).csv') %>% distinct(originalname, .keep_all=TRUE)


harmonized = all_dat_df %>% left_join(taxaharm, by=join_by("variablename" == "originalname")) %>% drop_na(correctedname)

harmonized %>% group_by(uncertainty) %>% count() %>% arrange(desc(n)) %>% datatable(rownames=FALSE,options = list(pageLength = 12))

## 2534 unmatched taxa from MDD_species 
## 2491 unmatched taxa from MDD_species
## 2316 unmatched taxa from Val's and Jessica's table
```

I made an uncertainty metric to measure site-level precision. I assigned a certainty score to each rank, such that species = 1, genus = 2, family = 3, and in-between values get half points:

```{r unc}

unc_values = c(3.5,2.5,1.5,3,2,2.5,2.5,4,1,1.5,1.5,2.5)

precision = harmonized %>% group_by(uncertainty) %>% count()

precision = precision$uncertainty
unc_converter = data.frame(values = unc_values, precision=precision)


datatable(unc_converter,rownames=FALSE,options = list(pageLength = 12))

unc_scores = harmonized %>% group_by(datasetid,variablename,uncertainty) %>% count()  %>% left_join(unc_converter,by=join_by(uncertainty == precision)) %>% ungroup() %>% group_by(datasetid) %>% summarize(score_prenormal =sum(values)) 

unc_total_tallies = harmonized %>% group_by(datasetid,variablename, uncertainty) %>% count()%>% ungroup() %>% group_by(datasetid) %>% count()

```

Then I checked at each site how many distinct identifications were made, summed the uncertainty value of those distinct identifications and divided by the total number of distinct identifications to get a site-level uncertainty metric. A value of 1 for a site would then mean that all the distinct identifications at that site were to species-precision. I did exclude all observations for which the taxon-harmonization table isn't ready (2316 taxa; 45,450 observations). 


The graph below shows how the uncertainty metric evolves with site-level taxonomic richness. The richest sites tend to have more precise identifications.

The map below shows the spatial distribution of taxonomic richness and uncertainty in separate layers.

```{r datharm}

unc_all = unc_scores %>% left_join(unc_total_tallies,by=join_by(datasetid)) %>% dplyr::mutate(unc_metric=score_prenormal/n)

vdf = vert_datasets %>% left_join(unc_all) %>% drop_na(unc_metric)


plot_vdf = ggplot(vdf) +
  geom_point(mapping=aes(x=n,
                         y=unc_metric,color=databasename,
                         text = paste(sitename,
                                 "<br>Taxonomic Richness", n,
                                 "<br>Uncertainty:", unc_metric)),alpha=0.4,stroke=NA) +
  theme_bw() +
  labs(x="Taxonomic Richness", y="Uncertainty") +
  guides(color = guide_legend(override.aes = list(
    linetype = 1,   # No line
    shape = 16,     # Solid circle
    size=2,
    alpha = 1 # Dot size
  ))) 

ggplotly(plot_vdf, tooltip="text")




point_unc = point_vert_datasets %>% left_join(vdf,by=join_by(datasetid)) %>% dplyr::filter(!is.na(unc_metric))

poly_unc = poly_vert_datasets %>% left_join(vdf,by=join_by(datasetid)) %>% dplyr::filter(!is.na(unc_metric))

library(RColorBrewer)

dark_palette <- brewer.pal(9, "YlOrBr")[1:9]

pal_unc <- colorNumeric(palette = dark_palette, domain = c(1,4))

pal_tax_rich = colorNumeric(palette="BuPu", domain=c(1,46))


m = leaflet() %>%
  addTiles() %>%
    addPolygons(data=poly_unc,
              fillColor=~pal_unc(unc_metric),
              color=~pal_unc(unc_metric),
              weight=2,
              opacity=0.5,
              fillOpacity=0.5,
              popup = ~link,
            group="Uncertainty") %>%
  addCircleMarkers(data=point_unc,
                   fillColor=~pal_unc(unc_metric),
                   stroke=FALSE,
                   radius=3,
                   fillOpacity=0.5,
                   popup = ~link,
                   group="Uncertainty") %>%
    addPolygons(data=poly_unc,
              fillColor=~pal_tax_rich(n),
              color=~pal_tax_rich(n),
              weight=2,
              opacity=0.5,
              fillOpacity=0.5,
              popup = ~link,
            group="Taxonomic Richness") %>%
  addCircleMarkers(data=point_unc,
                   fillColor=~pal_tax_rich(n),
                   stroke=FALSE,
                   radius=3,
                   fillOpacity=0.5,
                   popup = ~link,
            group="Taxonomic Richness") %>%
   addLegend("bottomright", 
            pal = pal_unc, 
            values = point_unc$unc_metric,
            title = "Uncertainty",
            opacity = 1,
            group="Uncertainty") %>%
   addLegend("bottomleft", 
            pal = pal_tax_rich, 
            values = point_unc$n,
            title = "Taxonomic Richness",
            opacity = 1,
            group="Taxonomic Richness") %>%
    addLayersControl(
    overlayGroups = c("Uncertainty", "Taxonomic Richness"),
    options = layersControlOptions(collapsed = FALSE)) %>%
      hideGroup("Taxonomic Richness")
m

  
```

Below is a graph that shows how precision has evolved over time. There's no obvious change over time.

```{r change-wth-time}

vdf = vert_datasets %>% left_join(unc_all) %>% drop_na(unc_metric)

time_vdf =ggplot(vdf) +
  geom_point(mapping=aes(x=dataset_date,y=unc_metric,color=databasename,
                         text = paste(sitename,
                                 "<br>Taxonomic Richness:", n,
                                 "<br>Uncertainty:", unc_metric)),alpha=0.4,stroke=NA) +
  theme_bw() +
  guides(color = guide_legend(override.aes = list(
    linetype = 1,   # No line
    shape = 16,     # Solid circle
    size=2,
    alpha = 1 # Dot size
  ))) 
ggplotly(time_vdf, tooltip="text")

```


## Taxonomic Coverage {.tabset}

Below are maps of two key species from every order of mammals. The following orders are not represented:

* Primates (except for <i>Homo</i>)
* Diprotodonts (no Australian sites)
* Dasyuromorphs (no Australian sites)
* Peramelemorphs (no Australian sites)
* Afrosoricida (no African sites)
* Macroscelidea (no African sites)
* Scandentia (no southeast Asian sites)
* Paucituberculata (few South American sites)
* Pholidota (few subtropical African and Asian sites)
* Hyracoidea
* Monotremes
* Dermoptera
* Notoryctemorphia
* Microbiotheria
* Tubulidentata

I also didn't consider extinct orders. I think <i>Psittacotherium multifragum</i> may be from an extinct order.

<div class="newgrid" id="mammals">
```{r mammal-maps}
#pbdb = content(GET("https://paleobiodb.org/data1.2/occs/list.txt?rowcount&base_name=Primates"))

#lines <- unlist(strsplit(api_string, "\r\n"))
#start_row <- which(grepl("^\"occurrence_no\"", lines))
#data_lines <- lines[start_row:length(lines)]
#csv_text <- paste(data_lines, collapse = "\n")
#pbdb_df <- read.csv(text = csv_text, stringsAsFactors = FALSE)

#pbdb_df %>% dplyr::filter(early_interval %in% c("Holocene","Gelasian","Middle Pleistocene","Piacenzian","Pleistocene","Late Pleistocene","Calabrian","Zanclean","Pliocene","Early Pleistocene","Late Pliocene")) %>% group_by(identified_name) %>% count() %>% arrange(desc(n))

#patterns = c("Homo", "Cercopithecidae", "Theropithecus","Rhinocolobus","Australopithecus","Paracolobus","Macaca","Papio","Parapapio")
#all_dat_df$variablename[Reduce(`|`, lapply(patterns, grepl, x = all_dat_df$variablename))]

#Primates
## Homo sapiens
#Diprotodonts
## Primarily Australia
#Dasyuromorphs
## Primarily Australia
#Afrosoricida
## Africa
#Macroscelidea
## Africa
#Peramelemorphs
## Australia
#Scandentia
## southeast Asia
#Paucituberculata
## South America
#Pholidota - pangolins
## subtropical Africa and Asia
#Hyracoidea
#Monotremes
#Dermoptera
##  Psittacotherium multifragum
#Notoryctemorphia
#Microbiotheria
#Tubulidentata

taxa_names=c("Microtus ochrogaster","Marmota flaviventris",
             "Eptesicus fuscus",  
"Myotis sp.",
"Scalopus aquaticus",
"Blarina brevicauda",
"Mylohyus fossilis",
"Camelops",
"Urocyon cinereoargenteus",
"Taxidea taxus",
"Sylvilagus floridanus",
"Brachylagus idahoensis",
"Equus conversidens",
"Tapirus veroensis",
"Mammut americanum",
"Mammuthus sp.",
"Didelphis virginiana",
"Didelphis marsupialis",
"Trichechus manatus",
"Trichechidae",
"Glyptotherium texanum",
"Dasypus bellus",
"Megalonyx jeffersonii",
"Paramylodon harlani")
orders=c("Rodents","Rodents",
         "Bats", "Bats",
         "Eulipotyphla","Eulipotyphla",
         "Artiodactyls","Artiodactyls",
         "Carnivorans","Carnivorans",
         "Lagomorphs","Lagomorphs",
         "Perissodactyls","Perissodactyls",
         "Proboscideans","Proboscideans",
         "Didelphimorphs", "Didelphimorphs",
         "Sirens","Sirens",
         "Cingulates","Cingulates",
         "Pilosa",
         "Pilosa")


map_list <- list()


for (i in seq(length(taxa_names))) {

name = taxa_names[i]
order = orders[i]

mochro_point = point_vert_datasets %>% dplyr::left_join(all_dat_df) %>% dplyr::filter(variablename==name) %>% distinct(datasetid,.keep_all = TRUE) %>% st_set_crs(st_crs(poly_vert_datasets))

mochro_poly  = poly_vert_datasets %>% dplyr::left_join(all_dat_df) %>% dplyr::filter(variablename==name) %>% distinct(datasetid,.keep_all = TRUE)


mochro_point = mochro_point %>% dplyr::mutate(link = paste0("<a target='_blank' href='https://data.neotomadb.org/datasets/",datasetid,"'/>",sitename,"</a>"))
mochro_poly = mochro_poly %>% dplyr::mutate(link = paste0("<a target='_blank' href='https://data.neotomadb.org/datasets/",datasetid,"'/>",sitename,"</a>"))

leg_names = mochro_point %>% select(databasename) %>% rbind(mochro_poly %>% select(databasename))
graph = leaflet() %>%
    addTiles() %>%
    addPolygons(data=mochro_poly,
                fillColor=~pal(databasename),
                color=~pal(databasename),
                weight=2,
                   fillOpacity=0.8,
                opacity=0.8,
                   popup = ~link) %>%
    addCircleMarkers(data=mochro_point,
                     fillColor=~pal(databasename),
                     stroke=FALSE,
                     radius=3,
                   fillOpacity=0.8,
                   popup = ~link)  %>%
    addLegend("bottomright", 
              pal = pal, 
              values = leg_names$databasename,
              title = "Database Name",
              opacity = 1)

title_html <- paste0("<h2>",name,"</h2>")

graph <- graph %>%
      addControl(html = title_html, position = "topright")

assign(paste0(gsub(" ", "_", name),"_map"),graph)

map_list[[name]] <- graph

}

#tagList(map_list)
```

```{r thing, results="asis"}

for (i in seq_along(taxa_names)) {
  name <- taxa_names[[i]]
  order <- orders[[i]]
  
  title <- paste0("### ", order, ": ", name)
  
  out <- htmltools::tagList(
    knitr::asis_output(paste0(title, "\n\n")),
    map_list[[name]]
  )
  
  print(out)
}
```
</div>


I matched taxa in Neotoma to taxa recoded by the Mammal Diversity Database, in order to get information on order, family, and genus for each identification.

The Mammal Diversity Database won't match taxa starting with ? or cf., or with sp. in the name, or extinct species. For ?, cf., and sp. or spp., I abstracted that from the Neotoma name to aid with the identifications. (I kept the presence or absence of those markers in a new column though, so it's not lost, but I haven't used that information in the below visualizations.)

I ended up matching 52,477 observations out of 78,415, and 1249 out of 2883 taxa. There's a bias toward missing all the extinct species, so you don't see the pilosa or cingulates from the Americas that you might otherwise

For the sake of simplicity, I ignore cf. and sp. in my table below. (But I retain that information in the dataframe.)

The graph below shows the representation among taxa matched to the MMD of the various mammal orders.

And below that, the table shows the number of distinct families, genera, and species represented in Neotoma for each order represented.

The reason that sirenia has two families but fewer genera and species is that only one of the Sirenia observations went to species-precision, while the other two only went to family, so I didn't count those two in the genera and species column. Similarly, proboscideans are not represented in the table but they are in the graph because there were MMD-matched taxa to order-precision for proboscideans, but nothing more precise than that. Of course, Neotoma has a lot of mammut and mammuthus, but those taxa IDs were not matched in the MMD, probably because the MMD seems only to concern itself with extant taxa. 


```{r new-cover}

library(stringr)

taxaharm2 = read.csv("Species_Syn_v2.2.csv") %>% distinct(MDD_original_combination,.keep_all=TRUE)


harm2 = all_dat_df %>% left_join(taxaharm2,by=join_by("variablename"=="MDD_original_combination")) %>% drop_na(MDD_order)

harm2_na = all_dat_df %>% left_join(taxaharm2,by=join_by("variablename"=="MDD_original_combination")) %>% dplyr::filter(is.na(MDD_order))

all_dat_df = all_dat_df %>% left_join(datasetdatabases_df,by=join_by(datasetid)) %>% left_join(constituentdatabases_df,by=join_by(databaseid))

all_dat_df$variablename15 <- gsub("^(\\?|cf\\.?|\\?\\s*cf\\.?)\\s*", "", all_dat_df$variablename)

all_dat_df = all_dat_df %>% dplyr::mutate(cf_or_q = case_when(variablename15 != variablename ~ 1,TRUE~ 0))

all_dat_df$variablename2 <- gsub("\\s+(sp\\.|spp\\.)$", "", all_dat_df$variablename15) 

all_dat_df = all_dat_df %>% dplyr::mutate(sp_spp = case_when(
  variablename15 != variablename2 ~ 1,TRUE~ 0))


harm3 = all_dat_df %>% left_join(taxaharm2,by=join_by("variablename2"=="MDD_original_combination")) %>% drop_na(MDD_order) %>% select(variablename2,MDD_genus,MDD_order,MDD_family,cf_or_q,sp_spp,databasename) %>% dplyr::mutate(certainty="species")

harm3_na = all_dat_df %>% left_join(taxaharm2,by=join_by("variablename2"=="MDD_original_combination")) %>% dplyr::filter(is.na(MDD_order))

harm3_distinct = harm3_na %>% distinct(variablename2)

mdd_genera = taxaharm2 %>% distinct(MDD_genus,.keep_all=TRUE)

harm4 = all_dat_df %>% dplyr::filter(variablename2 %in% harm3_distinct$variablename2) %>% left_join(mdd_genera,by=join_by("variablename2"=="MDD_genus")) %>% drop_na(MDD_order)  %>% dplyr::mutate(MDD_genus = variablename2) %>% select(variablename2,MDD_genus,MDD_order,MDD_family,cf_or_q,sp_spp,databasename) %>% dplyr::mutate(certainty="genus")


harm4_na = all_dat_df %>% dplyr::filter(variablename2 %in% harm3_distinct$variablename2) %>% left_join(mdd_genera,by=join_by("variablename2"=="MDD_genus")) %>% dplyr::filter(is.na(MDD_order)) 

harm4_distinct = harm4_na %>% distinct(variablename2)


mdd_families = taxaharm2 %>% distinct(MDD_family,.keep_all=TRUE)

harm5 = all_dat_df %>% dplyr::filter(variablename2 %in% harm4_distinct$variablename2) %>% left_join(mdd_families,by=join_by("variablename2"=="MDD_family")) %>% drop_na(MDD_order)  %>% dplyr::mutate(MDD_family = variablename2) %>% select(variablename2,MDD_genus,MDD_order,MDD_family,cf_or_q,sp_spp,databasename) %>% dplyr::mutate(certainty="family")


harm5_na =  all_dat_df %>% dplyr::filter(variablename2 %in% harm4_distinct$variablename2) %>% left_join(mdd_families,by=join_by("variablename2"=="MDD_family")) %>% dplyr::filter(is.na(MDD_order))

harm5_distinct = harm5_na %>% distinct(variablename2)


mdd_orders = taxaharm2 %>% distinct(MDD_order,.keep_all=TRUE)

harm6 = all_dat_df %>% dplyr::filter(variablename2 %in% harm5_distinct$variablename2) %>% left_join(mdd_orders,by=join_by("variablename2"=="MDD_order")) %>% drop_na(MDD_species)  %>%
  dplyr::mutate(MDD_order = variablename2) %>% select(variablename2,MDD_genus,MDD_order,MDD_family,cf_or_q,sp_spp,databasename) %>% dplyr::mutate(certainty="order")


harm6_na =  all_dat_df %>% dplyr::filter(variablename2 %in% harm5_distinct$variablename2) %>% left_join(mdd_orders,by=join_by("variablename2"=="MDD_order")) %>% dplyr::filter(is.na(MDD_species))

harm6_distinct = harm6_na %>% distinct(variablename2)


all_harm = harm3 %>% rbind(harm4) %>% rbind(harm5) %>% rbind(harm6)


##1790 unmatched taxa in harm3
##1634 in harm6


all_harm$MDD_order <- factor(all_harm$MDD_order, levels = c("Rodentia", "Carnivora", "Artiodactyla","Lagomorpha","Eulipotyphla","Chiroptera","Perissodactyla","Didelphimorphia","Proboscidea","Cingulata","Pilosa","Sirenia","Primates"))

ggplot(all_harm) +
  geom_bar(mapping=aes(x=MDD_order,fill=databasename)) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))

famharm = all_harm %>% group_by(MDD_order) %>% dplyr::filter(certainty != "order") %>% distinct(MDD_family) %>% count() %>% arrange(desc(n))

names(famharm) = c("order","number families")

genharm = all_harm %>% group_by(MDD_order) %>% dplyr::filter(!certainty %in% c("order","family")) %>% distinct(MDD_genus) %>% count() %>% arrange(desc(n))

names(genharm) = c("order","number genera")


specharm = all_harm %>% group_by(MDD_order) %>% dplyr::filter(!certainty %in% c("order","family","genus")) %>% distinct(variablename2) %>% count() %>% arrange(desc(n))

names(specharm) = c("order","number species")

famharm %>% left_join(genharm) %>% left_join(specharm) %>% datatable(rownames=FALSE,options = list(pageLength = 12))

```


<div class="tocify-extend-page" data-unique="tocify-extend-page" style="height: 0;"></div>
